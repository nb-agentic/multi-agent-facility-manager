# IntelliCenter Environment Configuration
# Ollama Configuration
OLLAMA_HOST=http://localhost:11434
OLLAMA_NUM_PARALLEL=1
OLLAMA_MAX_LOADED_MODELS=2
OLLAMA_FLASH_ATTENTION=true

# CrewAI Configuration  
CREWAI_LLM_PROVIDER=ollama
CREWAI_MODEL=mistral:7b

# Disable Telemetry
OTEL_SDK_DISABLED=true
OPENAI_API_KEY=sk-fake-key-for-local-llm

# Performance Settings
PYTHONUNBUFFERED=1
PYTHONDONTWRITEBYTECODE=1
